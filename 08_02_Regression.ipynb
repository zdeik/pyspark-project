{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54674565-66f4-4443-b807-3431eee00e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "MAX_MEMORY = '8g'\n",
    "\n",
    "spark = SparkSession.builder.appName('taxi-fare-prediction_2nd') \\\n",
    "    .config('spark.driver.memory', MAX_MEMORY) \\\n",
    "    .config('spark.executor.memory', MAX_MEMORY) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6708f36a-ab8a-49e5-b863-b6a67f75e921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd =os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, 'learning_spark_data','trips','*.csv')\n",
    "file_path = f\"file:///{trip_data_path.replace(os.sep,'/') }\"\n",
    "trip_df = spark.read.csv(file_path, inferSchema=True, header=True)\n",
    "trip_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ee141a-69a4-4aa0-88ec-6db3daa197e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.createOrReplaceTempView('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56672d4-defe-4e4a-a225-989ef65f55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    PULocationID AS pickup_location_id,\n",
    "    DOLocationID AS dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) AS pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "    total_amount\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53df0deb-3a86-4ac4-bd0d-6b88e7f3bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df = spark.sql(query)\n",
    "trip_df.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1466ae-5299-4ec1-a396-3d527091c29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|               138|                265|         16.5|          0|     Monday|       70.07|\n",
      "|              1|                68|                264|         1.13|          0|     Monday|       11.16|\n",
      "|              1|               239|                262|         2.68|          0|     Monday|       18.59|\n",
      "|              1|               186|                 91|         12.4|          0|     Monday|        43.8|\n",
      "|              2|               132|                265|          9.7|          0|     Monday|        32.3|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT * \n",
    "FROM DATA\n",
    "LIMIT 5\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106aa0af-1590-4b00-96ce-8855eebafc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할\n",
    "train_data, test_data = trip_df.randomSplit([0.8, 0.2], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23f4a3-16b3-41f1-9e17-d51350ea5442",
   "metadata": {},
   "source": [
    "# 파이프라인 생성\n",
    "- 전처리 과정을 각 스테이지로 정의해서 쌓는다\n",
    "- 범주형] StringIndexer+onehotencoding : 'pickup_location_id', 'dropoff_location_id', 'day_of_week'\r",
    "- \n",
    "수치형] StandardScaler : 'passenger_count', 'trip_distance', 'pickup_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f3c8e2-e898-4e9d-9055-c7eb3e42e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05dca3a-9ea0-4d02-a1bd-62e5cd5f089c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_1d841b1c3348,\n",
       " OneHotEncoder_f2fc04206797,\n",
       " StringIndexer_a19fae2c13dc,\n",
       " OneHotEncoder_a7fc6d014518,\n",
       " StringIndexer_71fef2e295e2,\n",
       " OneHotEncoder_8d0057f5447a]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "cat_features = ['pickup_location_id', 'dropoff_location_id', 'day_of_week']\n",
    "for cat in cat_features:\n",
    "    cat_index = StringIndexer(inputCol=cat, outputCol=cat+'_idx').setHandleInvalid('keep')\n",
    "    onehot_encode = OneHotEncoder(inputCols= [cat_index.getOutputCol()], #_idx col\n",
    "                                  outputCols=[cat+'_onehot'] #postfix\n",
    "                                 )\n",
    "    stages += [cat_index, onehot_encode ] #collist\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb3d509-b2d2-42ae-893a-74a7c5de3839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_1d841b1c3348,\n",
       " OneHotEncoder_f2fc04206797,\n",
       " StringIndexer_a19fae2c13dc,\n",
       " OneHotEncoder_a7fc6d014518,\n",
       " StringIndexer_71fef2e295e2,\n",
       " OneHotEncoder_8d0057f5447a,\n",
       " VectorAssembler_031b9ebd593b,\n",
       " StandardScaler_dbef57a69110,\n",
       " VectorAssembler_a6ff3f6e0581,\n",
       " StandardScaler_10d716ae61a4,\n",
       " VectorAssembler_f93e50d02e23,\n",
       " StandardScaler_19a869957674]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "num_features = ['passenger_count', 'trip_distance', 'pickup_time']\n",
    "\n",
    "for num in num_features:\n",
    "    num_assembler = VectorAssembler(inputCols=[num], outputCol=num+'_vector')\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=num+'_scaled')\n",
    "    stages += [num_assembler, num_scaler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d14b622-67f7-4200-a497-213c0fd627e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler_input = [cat + '_onehot' for cat in cat_features] + [num+ '_scaled' for num in num_features]\n",
    "assembler_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b69c1-f946-443f-8af2-27d776c4ab52",
   "metadata": {},
   "source": [
    "선형회귀 모델 - 값들이 수치형\n",
    "data_df = feature(6) + label(1)\n",
    "cat_feature = 3 -> StringIndexer+OneHotEncoder\n",
    "num_feature = 3 -> VectorAssembler + StandardScaler\n",
    "각 피처마다 2단계에 걸쳐 전처리\n",
    "총6개 피처 -> 2단계 ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b0d5bc-1ac2-4380-a9c6-e3a32cb361b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_1d841b1c3348,\n",
       " OneHotEncoder_f2fc04206797,\n",
       " StringIndexer_a19fae2c13dc,\n",
       " OneHotEncoder_a7fc6d014518,\n",
       " StringIndexer_71fef2e295e2,\n",
       " OneHotEncoder_8d0057f5447a,\n",
       " VectorAssembler_031b9ebd593b,\n",
       " StandardScaler_dbef57a69110,\n",
       " VectorAssembler_a6ff3f6e0581,\n",
       " StandardScaler_10d716ae61a4,\n",
       " VectorAssembler_f93e50d02e23,\n",
       " StandardScaler_19a869957674,\n",
       " VectorAssembler_b9c430d737d0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_input, outputCol='feature_vector')\n",
    "stages+= [assembler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd75fb7-0d77-4ded-a4af-0b1fb9ee7817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vector: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transform = pipeline.fit(train_data)\n",
    "vector_df = fitted_transform.transform(train_data) # 백터화된 train_data\n",
    "vector_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4484b2c-7077-439b-a2c0-3172c6fa2319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      feature_vector|\n",
      "+--------------------+\n",
      "|(533,[62,311,527,...|\n",
      "|(533,[62,280,526,...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_df.select('feature_vector').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38917aa3-10b8-453e-98b9-d84b8f6b405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=50, featuresCol='feature_vector', labelCol='total_amount')\n",
    "model = lr.fit(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f98e0ff-bbaa-4c06-b6c6-a98453024393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vector: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터도 변환\n",
    "ytest_df = fitted_transform.transform(test_data)\n",
    "ytest_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68abbd1d-12ae-4a85-9529-c1a70c8473b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(ytest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e56c1bc-5910-4650-bb0d-3bbed06cb7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|total_amount|        prediction|\n",
      "+------------+------------------+\n",
      "|       10.55|12.695522792729275|\n",
      "|        13.3|14.450558014776915|\n",
      "|        21.3|21.108271361254218|\n",
      "|        41.3| 40.87993984204378|\n",
      "|       14.15|13.906932982613997|\n",
      "+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select('total_amount', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58bb69c-0eaa-4b70-af76-546380238be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cad528-e79a-43d2-9df3-67d6470b8939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d987a20-b3ed-4ee0-b6a2-d7e7b49240d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57de1e-eb7b-4f72-92e5-ee90084bfe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a819294-04be-4cf9-8f43-f283abde74e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90bf7b-10c0-4240-af19-8a11fdd89381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
