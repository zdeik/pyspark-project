{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b0415a0-25f3-46b5-bbce-6b50c432bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73124cac-67c3-458a-a643-78dd50067938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"spark_sql_basic2\")\n",
    "sc   = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57c755ee-9483-45d9-8790-cb8507c97f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD만을 이용한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62064931-39fb-4d70-bb94-ecc6300b3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_rdd = sc.parallelize([\n",
    "    (1, (\"어벤져스\", \"마블\")),\n",
    "    (2, (\"슈퍼맨\", \"DC\")),\n",
    "    (3, (\"배트맨\", \"DC\")),\n",
    "    (4, (\"겨울왕국\", \"디즈니\")),\n",
    "    (5, (\"아이언맨\", \"마블\"))\n",
    "])\n",
    "\n",
    "\n",
    "attendances_rdd = sc.parallelize([\n",
    "    (1, (13934592, \"KR\")),\n",
    "    (2, (2182227,\"KR\")),\n",
    "    (3, (4226242, \"KR\")),\n",
    "    (4, (10303058, \"KR\")),\n",
    "    (5, (4300365, \"KR\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee708262-d2a1-428a-90b4-5420d8cac134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마블 영화 중 관객 수가 500만 이상인 영화를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46572ff5-443f-4eb7-9bd8-9d2f29f28b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CASE1. join 먼저, filter 나중에\n",
    "movie_att = movies_rdd.join(attendances_rdd)\n",
    "movie_att.filter(\n",
    "    lambda x : x[1][0][1] == \"마블\" and x[1][1][0] > 5000000\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a39b1043-e899-4a72-8a63-0c4e70ff428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CASE 2. filter 먼저, join 나중에\n",
    "filtered_movies = movies_rdd.filter(lambda x : x[1][1] == '마블')\n",
    "filtered_att = attendances_rdd.filter(lambda x : x[1][0] > 5000000)\n",
    "\n",
    "filtered_movies.join(filtered_att).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bf221e2-7894-44af-95b1-673a828aaa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark SQL 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d6a6be2-6364-42ad-972f-ee733e41b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d704416-8c08-42dd-abcb-c7c10b3de900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 추가\n",
    "movies = [\n",
    "    (1, \"어벤져스\", \"마블\", 2012, 4, 26),\n",
    "    (2, \"슈퍼맨\", \"DC\", 2013, 6, 13),\n",
    "    (3, \"배트맨\", \"DC\", 2008, 8, 6),\n",
    "    (4, \"겨울왕국\", \"디즈니\", 2014, 1, 16),\n",
    "    (5, \"아이언맨\", \"마블\", 2008, 4, 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "445a1c74-a982-41b3-b420-81391fa8035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스키마를 알아야 한다.\n",
    "movie_schema = [\"id\", \"name\", \"company\", \"year\", \"month\", \"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86f8b433-d021-4fb2-bdd2-5ec2e89934e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9d4f62e-fac5-42f7-9c42-6ce6edaf3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=movies, schema=movie_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ff4f4969-80e2-4926-a2ca-63d09f45a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|  배트맨|\n",
      "|겨울왕국|\n",
      "|아이언맨|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20312673-ba68-45f6-8c39-d79f6687285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.year >= 2010).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9daf939-9807-4f83-a082-8bc47b50aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bd2369ec-d17d-4c07-87e2-75f236509f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|  배트맨|\n",
      "|겨울왕국|\n",
      "|아이언맨|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 영화 이름만 가져오기\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT name\n",
    "  FROM movies\n",
    "\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c4ccd990-57d8-454a-8fb9-41c2c3f1989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f24eb187-722d-495b-af67-a375318d5ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|    name|year|\n",
      "+--------+----+\n",
      "|어벤져스|2012|\n",
      "|  슈퍼맨|2013|\n",
      "|겨울왕국|2014|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2010년 이후에 개봉한 영화를 조회\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT name, year\n",
    "FROM movies\n",
    "WHERE year > 2010\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "733a6585-3b8e-43ef-9686-3e545c56a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|    name|company|\n",
      "+--------+-------+\n",
      "|어벤져스|   마블|\n",
      "|  배트맨|     DC|\n",
      "|아이언맨|   마블|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2012년도 이전에 개봉한 영화의 이름과 회사를 출력\n",
    "query = \"\"\"\n",
    "SELECT name, company\n",
    "FROM movies\n",
    "WHERE year <= 2012\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "275a37e2-975c-4ffb-afd8-93f3fc7d9a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like 문자열 데이터에서 특정 단어나 문장을 포함한 데이터를 찾을 때\n",
    "# % 기호를 사용해서 문장이 매칭되는지 확인 가능!\n",
    "# 제목이 ~~맨으로 끝나는 데이터의 모든 정보를 조회\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM movies\n",
    "WHERE name LIKE '%맨'\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fbc1e78e-3314-434c-ae29-0d698ceb5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BETWEEN 특정 데이터와 데이터 사이를 조회\n",
    "\n",
    "# 개봉 월이 4 ~ 8월 사이. 4 <= 개봉월 <= 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "92d0a753-fac1-4151-a016-c09511132f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM movies\n",
    "WHERE month BETWEEN 4 AND 8\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20690144-20a2-4126-888c-b1074bd835bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc365151-3703-444c-a100-48ad4046e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attendances = [\n",
    "    (1, 13934592., \"KR\"),\n",
    "    (2, 2182227.,\"KR\"),\n",
    "    (3, 4226242., \"KR\"),\n",
    "    (4, 10303058., \"KR\"),\n",
    "    (5, 4300365., \"KR\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e395f667-08ab-4e02-bbf8-dad62b1b9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 스키마 지정해 보기\n",
    "from pyspark.sql.types import StringType, FloatType\\\n",
    "    , IntegerType\\\n",
    "    , StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "406d3d10-b99b-4677-b203-459d4e73b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_schema = StructType([ # 모든 컬럼의 타입을 통칭 - 컬럼 데이터의 집합\n",
    "    StructField(\"id\", IntegerType(), True), # StructField : 컬럼\n",
    "    StructField(\"att\", FloatType(), True),\n",
    "    StructField(\"theater_country\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5c49e812-3a29-4b4b-8de1-3ad36b1da102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'), ('att', 'float'), ('theater_country', 'string')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "att_df = spark.createDataFrame(\n",
    "    data=attendances,\n",
    "    schema=att_schema\n",
    ")\n",
    "\n",
    "att_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "79d1c138-86c5-4ddd-812e-301655451a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df.createOrReplaceTempView(\"att\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aade8ee3-db29-4049-bc36-8a3ae65495bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------------+\n",
      "| id|        att|theater_country|\n",
      "+---+-----------+---------------+\n",
      "|  1|1.3934592E7|             KR|\n",
      "|  2|  2182227.0|             KR|\n",
      "|  3|  4226242.0|             KR|\n",
      "|  4|1.0303058E7|             KR|\n",
      "|  5|  4300365.0|             KR|\n",
      "+---+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "att_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e28ade1-0b13-4494-a968-b87ee30df0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-----------+\n",
      "| id|    name|company|        att|\n",
      "+---+--------+-------+-----------+\n",
      "|  1|어벤져스|   마블|1.3934592E7|\n",
      "|  2|  슈퍼맨|     DC|  2182227.0|\n",
      "|  3|  배트맨|     DC|  4226242.0|\n",
      "|  4|겨울왕국| 디즈니|1.0303058E7|\n",
      "|  5|아이언맨|   마블|  4300365.0|\n",
      "+---+--------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df와att_df join\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    m.id, m.name, m.company, a.att\n",
    "FROM movies m\n",
    "JOIN att a\n",
    "ON m.id = a.id\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c52cb8-cce9-4700-ae4d-0b50e4a1922b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea8b49-beed-46a0-ab5e-220852e30aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ec5e568-23bb-47a0-9c9a-d8ee8581c684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='어벤져스', company='마블', year=2012, month=4, day=26),\n",
       " Row(id=2, name='슈퍼맨', company='DC', year=2013, month=6, day=13),\n",
       " Row(id=3, name='배트맨', company='DC', year=2008, month=8, day=6),\n",
       " Row(id=4, name='겨울왕국', company='디즈니', year=2014, month=1, day=16),\n",
       " Row(id=5, name='아이언맨', company='마블', year=2008, month=4, day=30)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select\n",
    "df.select(\"*\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73334616-316a-47ba-bbca-3780b58fe6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='어벤져스', company='마블'),\n",
       " Row(name='슈퍼맨', company='DC'),\n",
       " Row(name='배트맨', company='DC'),\n",
       " Row(name='겨울왕국', company='디즈니'),\n",
       " Row(name='아이언맨', company='마블')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"name\", \"company\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40db9364-606b-4974-873a-5fd5ef3a8918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|    name|year|\n",
      "+--------+----+\n",
      "|어벤져스|  12|\n",
      "|  슈퍼맨|  13|\n",
      "|  배트맨|   8|\n",
      "|겨울왕국|  14|\n",
      "|아이언맨|   8|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, (df.year-2000).alias(\"year\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb58352-d6b8-4545-a335-632d52473def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(id)=5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agg : Aggreagte의 약자로써, 그룹핑 후 데이터를 하나로 합쳐주는 역할\n",
    "df.agg({\"id\": \"count\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c9f7c-6836-4924-8f08-b01e5272d541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51212c6f-0199-49ba-9995-09783594c41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(year)=2008)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.agg(F.min(df.year)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec3f7a-c11a-4aa8-b50c-9abfd0eb806c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "336d60a1-222c-4e5a-8a73-ec74fc187862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(id)=3.0, avg(year)=2011.0, avg(month)=4.6, avg(day)=18.2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy().avg().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03955127-cabe-4020-803a-d80605ec090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(company='디즈니', avg(month)=1.0),\n",
       " Row(company='마블', avg(month)=4.0),\n",
       " Row(company='DC', avg(month)=7.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회사별 개봉월의 평균\n",
    "df.groupBy('company').agg({\"month\": \"mean\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94641161-4fda-4170-97a6-0f04728b4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사 별 월 별 영화 개수 정보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8807e25-22f4-439a-91fe-e51c5ce34f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    name|        att|\n",
      "+--------+-----------+\n",
      "|어벤져스|1.3934592E7|\n",
      "|  슈퍼맨|  2182227.0|\n",
      "|  배트맨|  4226242.0|\n",
      "|겨울왕국|1.0303058E7|\n",
      "|아이언맨|  4300365.0|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join : 다른 데이터 프레임과 사용자가 지정한 컬럼을 기준으로 합치는 작업\n",
    "df.join(att_df, 'id').select(df.name, att_df.att).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973769b0-f1cd-4b87-8172-805f3bcdce85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15abf176-7d4b-4233-bba1-bd032c66ef63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='어벤져스', company='마블', year=2012),\n",
       " Row(name='아이언맨', company='마블', year=2008)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select, where, orderBy 절 사용\n",
    "marvel_df = df.select(\"name\", \"company\", \"year\").where(\"company=='마블'\").orderBy(\"id\")\n",
    "marvel_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "195c87a5-3db2-41d8-a6da-b47d6e030e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e73ebc-729c-40d5-b74f-71cc3a433f86",
   "metadata": {},
   "source": [
    "# fhvhv_tripdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c205c-c9d3-4f7f-90bf-aeeffda08ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6824043e-9457-4f3f-9ca5-f3aa89b29087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"trip_count_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "00b00cb7-73f7-4011-8b53-b0df55938fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_file = \"learning_spark_data/fhvhv_tripdata_2020-03.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "071ddd29-2ab5-412b-be45-0d067175d321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inferSchema : 자동으로 스키마 예측하게 하기\n",
    "data = spark.read.csv(trip_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9fdfa452-8e10-4401-802c-b7fb1df93aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"mobility_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9d4843ad-cdc8-40de-9970-9e8ba15b32bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   NULL|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   NULL|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select *\n",
    "from mobility_data\n",
    "limit 5\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f9776-6194-4eeb-9144-96f88802f396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1d66a4b-91a8-4013-9c4f-1528b4799c51",
   "metadata": {},
   "source": [
    "# 스파크 SQL을 사용하는 이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6b8134e5-bb59-411d-9d1c-c31bb358beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|pickup_date| trips|\n",
      "+-----------+------+\n",
      "| 2020-03-03|697880|\n",
      "| 2020-03-02|648986|\n",
      "| 2020-03-01|784246|\n",
      "| 2020-03-06|872012|\n",
      "| 2020-03-05|731165|\n",
      "| 2020-03-04|707879|\n",
      "| 2020-03-09|628940|\n",
      "| 2020-03-08|731222|\n",
      "| 2020-03-07|886071|\n",
      "| 2020-03-10|626474|\n",
      "| 2020-03-12|643257|\n",
      "| 2020-03-11|628601|\n",
      "| 2020-03-16|391518|\n",
      "| 2020-03-13|660914|\n",
      "| 2020-03-15|448125|\n",
      "| 2020-03-14|569397|\n",
      "| 2020-03-26|141607|\n",
      "| 2020-03-25|141088|\n",
      "| 2020-03-20|261900|\n",
      "| 2020-03-24|141686|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "select split(pickup_datetime, ' ')[0] as pickup_date, count(*) as trips\n",
    "from mobility_data\n",
    "\n",
    "group by pickup_date\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "30eb5a6f-2246-4e55-b6f1-aef9fdce364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['split('pickup_datetime,  )[0] AS pickup_date#1154, 'count(1) AS trips#1155]\n",
      "+- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [split(cast(pickup_datetime#1038 as string),  , -1)[0]], [split(cast(pickup_datetime#1038 as string),  , -1)[0] AS pickup_date#1154, count(1) AS trips#1155L]\n",
      "+- SubqueryAlias mobility_data\n",
      "   +- View (`mobility_data`, [hvfhs_license_num#1036,dispatching_base_num#1037,pickup_datetime#1038,dropoff_datetime#1039,PULocationID#1040,DOLocationID#1041,SR_Flag#1042])\n",
      "      +- Relation [hvfhs_license_num#1036,dispatching_base_num#1037,pickup_datetime#1038,dropoff_datetime#1039,PULocationID#1040,DOLocationID#1041,SR_Flag#1042] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [_groupingexpression#1159], [_groupingexpression#1159 AS pickup_date#1154, count(1) AS trips#1155L]\n",
      "+- Project [split(cast(pickup_datetime#1038 as string),  , -1)[0] AS _groupingexpression#1159]\n",
      "   +- Relation [hvfhs_license_num#1036,dispatching_base_num#1037,pickup_datetime#1038,dropoff_datetime#1039,PULocationID#1040,DOLocationID#1041,SR_Flag#1042] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[_groupingexpression#1159], functions=[count(1)], output=[pickup_date#1154, trips#1155L])\n",
      "   +- Exchange hashpartitioning(_groupingexpression#1159, 200), ENSURE_REQUIREMENTS, [plan_id=1228]\n",
      "      +- HashAggregate(keys=[_groupingexpression#1159], functions=[partial_count(1)], output=[_groupingexpression#1159, count#1161L])\n",
      "         +- Project [split(cast(pickup_datetime#1038 as string),  , -1)[0] AS _groupingexpression#1159]\n",
      "            +- FileScan csv [pickup_datetime#1038] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/learning_spark_data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 계획 살펴보기\n",
    "spark.sql(query).explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de790c06-75d5-4f02-b4e0-213444ef1297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6d5fe4a0-a753-4fc1-b80a-67e49b31b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['pickup_date, 'count(1) AS trips#1163]\n",
      "+- 'SubqueryAlias __auto_generated_subquery_name\n",
      "   +- 'Project ['split('pickup_datetime,  )[0] AS pickup_date#1162]\n",
      "      +- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [pickup_date#1162], [pickup_date#1162, count(1) AS trips#1163L]\n",
      "+- SubqueryAlias __auto_generated_subquery_name\n",
      "   +- Project [split(cast(pickup_datetime#1038 as string),  , -1)[0] AS pickup_date#1162]\n",
      "      +- SubqueryAlias mobility_data\n",
      "         +- View (`mobility_data`, [hvfhs_license_num#1036,dispatching_base_num#1037,pickup_datetime#1038,dropoff_datetime#1039,PULocationID#1040,DOLocationID#1041,SR_Flag#1042])\n",
      "            +- Relation [hvfhs_license_num#1036,dispatching_base_num#1037,pickup_datetime#1038,dropoff_datetime#1039,PULocationID#1040,DOLocationID#1041,SR_Flag#1042] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [pickup_date#1162], [pickup_date#1162, count(1) AS trips#1163L]\n",
      "+- Project [split(cast(pickup_datetime#1038 as string),  , -1)[0] AS pickup_date#1162]\n",
      "   +- Relation [hvfhs_license_num#1036,dispatching_base_num#1037,pickup_datetime#1038,dropoff_datetime#1039,PULocationID#1040,DOLocationID#1041,SR_Flag#1042] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[pickup_date#1162], functions=[count(1)], output=[pickup_date#1162, trips#1163L])\n",
      "   +- Exchange hashpartitioning(pickup_date#1162, 200), ENSURE_REQUIREMENTS, [plan_id=1243]\n",
      "      +- HashAggregate(keys=[pickup_date#1162], functions=[partial_count(1)], output=[pickup_date#1162, count#1168L])\n",
      "         +- Project [split(cast(pickup_datetime#1038 as string),  , -1)[0] AS pickup_date#1162]\n",
      "            +- FileScan csv [pickup_datetime#1038] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/learning_spark_data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두번째 쿼리\n",
    "spark.sql(\"\"\"select \n",
    "                pickup_date, \n",
    "                count(*) as trips\n",
    "             from ( select\n",
    "                          split(pickup_datetime, ' ')[0] as pickup_date\n",
    "                          from mobility_data )\n",
    "             group by pickup_date\"\"\").explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7c30c-cc77-4568-9f54-b9f3bf496675",
   "metadata": {},
   "source": [
    "| 비교 항목         | 첫 번째 방식        | 두 번째 방식                        |\n",
    "| ------------- | -------------- | ------------------------------ |\n",
    "| 코드 길이         | 짧고 간단함         | 구조적으로 명확함                      |\n",
    "| 중첩 쿼리         | 없음             | 있음 (가독성 및 재사용 ↑)               |\n",
    "| Spark Plan 관점 | 내부적으로는 거의 동일   | 동일 (결과와 성능 차이 거의 없음)           |\n",
    "| 추천 상황         | 빠른 실습, 간단한 분석용 | 복잡한 파생 컬럼 처리 시, 명확한 로직 표현 필요 시 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c89265-c529-451d-8609-06174749af18",
   "metadata": {},
   "source": [
    "# spark 사용이유\n",
    "| 이유                         | 설명                                           |\n",
    "| -------------------------- | -------------------------------------------- |\n",
    "| **쿼리 작성 방식이 달라도 성능은 동일** | Catalyst가 의미적으로 동일한 쿼리를 같은 방식으로 실행           |\n",
    "| **최적화는 Spark가 자동으로**     | 사용자는 로직에 집중, Spark는 내부에서 최적 실행 계획 생성         |\n",
    "| **생산성과 성능을 모두 보장**       | SQL, DataFrame 등 다양한 인터페이스를 통해 효율적 데이터 분석 가능 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31f58f-976e-4bfb-926a-640328a27811",
   "metadata": {},
   "source": [
    "# 결론\n",
    "위 두 방식의 비교는 Spark Catalyst Optimizer가 의미적으로 같은 쿼리를 동일한 방식으로 최적화해서 실행한다는 강력한 증거이다.\n",
    "따라서 Spark를 쓰면 \"내가 쿼리를 복잡하게 최적화하지 않아도 Spark가 내부적으로 해준다\"는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3b16eeb8-7ef8-43df-ae25-9e00ac192161",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7a3a0-1511-40af-99a1-203a3e0c7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bf582076-c610-432e-8445-d19279ff7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_file = \"learning_spark_data/fhvhv_tripdata_2020-03.csv\"\n",
    "zone_file = \"learning_spark_data/taxi+_zone_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "42ac5be1-c91c-43ad-a273-4489171883d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"trip_count_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "787fc1e9-a5bd-4bfc-8952-96e116d6faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#운행 데이터 프레임 생성, Zone 데이터프레임 생성\n",
    "trip_data = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('learning_spark_data/fhvhv_tripdata_2020-03.csv')\n",
    "zone_data = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('learning_spark_data/taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d80650c4-b4b4-4b94-9370-44a959ddad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "990abfef-d5b5-437e-94a4-152d6d3ee5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "849fef1e-a88d-43b5-b513-aaa6a9516ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   NULL|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   NULL|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee74331-4e29-4372-aaba-bc574a36a595",
   "metadata": {},
   "source": [
    "| 컬럼명                    | 한글 설명               | 예시                  |\n",
    "| ---------------------- | ------------------- | ------------------- |\n",
    "| `hvfhs_license_num`    | 운송사업자 코드            | HV0003, HV0005 등    |\n",
    "| `dispatching_base_num` | 배차된 기지 번호           | B02764 등            |\n",
    "| `pickup_datetime`      | 승차 시각               | 2020-03-01 00:03:40 |\n",
    "| `dropoff_datetime`     | 하차 시각               | 2020-03-01 00:23:39 |\n",
    "| `PULocationID`         | 승차 지점의 Location ID  | 81, 168 등           |\n",
    "| `DOLocationID`         | 하차 지점의 Location ID  | 159, 119 등          |\n",
    "| `SR_Flag`              | 공유 승차 여부 (값이 없거나 1) | NULL 또는 1           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "83689de2-3ab6-462f-b0ef-cbb71341de09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d637c5e-74b0-4be5-9ec2-51c59a0bc52a",
   "metadata": {},
   "source": [
    "| 컬럼명            | 한글 설명             | 예시                       |\n",
    "| -------------- | ----------------- | ------------------------ |\n",
    "| `LocationID`   | 지역 고유 ID          | 1, 2, 3 등                |\n",
    "| `Borough`      | 자치구(행정구역)         | Manhattan, Bronx 등       |\n",
    "| `Zone`         | 세부 지역명            | Alphabet City 등          |\n",
    "| `service_zone` | 서비스 존 (택시 서비스 구분) | Yellow Zone, Boro Zone 등 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "facf62ae-a94e-4694-93a2-97d5c04d88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.createOrReplaceTempView(\"trip_data\")\n",
    "zone_data.createOrReplaceTempView(\"zone_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3193c-fda2-4f33-98f6-144eca7ba470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 승차 Location(PULocationID)별 개수 세기\n",
    "# 하차 Location(DOLocationID)별 개수 세기\n",
    "#HV0003 운송사업자의 승차 지역별 트립 건수를 집계하고, \n",
    "#가장 많은 운송사업자순으로 정렬하는 분석 쿼리  hvfhs_license_num\n",
    "#운송사별 운행 건수 비교\n",
    "#승차 위치 Borough별 운행 건수\n",
    "#서비스 존별 승차/하차 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d1956f33-dedc-4ce5-bda0-146da98b2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|PULocationID|trip_count|\n",
      "+------------+----------+\n",
      "|          61|    222094|\n",
      "|          79|    183821|\n",
      "|          76|    168311|\n",
      "|         132|    163734|\n",
      "|         138|    155876|\n",
      "|          37|    155388|\n",
      "|          42|    143389|\n",
      "|         231|    135712|\n",
      "|         234|    132693|\n",
      "|         161|    128751|\n",
      "|         244|    126621|\n",
      "|          17|    126228|\n",
      "|           7|    125458|\n",
      "|          89|    124289|\n",
      "|         225|    124001|\n",
      "|         170|    122731|\n",
      "|         230|    121628|\n",
      "|         181|    121576|\n",
      "|          48|    120732|\n",
      "|          39|    116669|\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 승차 Location(PULocationID)별 개수 세기\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT PULocationID, COUNT(*) AS trip_count\n",
    "    FROM trip_data\n",
    "    GROUP BY PULocationID\n",
    "    ORDER BY trip_count DESC\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "631fb7ea-b58c-44a4-9988-156a2f908c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|DOLocationID|trip_count|\n",
      "+------------+----------+\n",
      "|         265|    387758|\n",
      "|          61|    224476|\n",
      "|         132|    216213|\n",
      "|         138|    194943|\n",
      "|          76|    172649|\n",
      "|          37|    158832|\n",
      "|          79|    147732|\n",
      "|          42|    136729|\n",
      "|         225|    128945|\n",
      "|          17|    128152|\n",
      "|         244|    127797|\n",
      "|          89|    126958|\n",
      "|           7|    124255|\n",
      "|         161|    121771|\n",
      "|         234|    118345|\n",
      "|         181|    116900|\n",
      "|         231|    116345|\n",
      "|          39|    113966|\n",
      "|         188|    113280|\n",
      "|         170|    109306|\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 하차 Location(DOLocationID)별 개수 세기\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT DOLocationID, COUNT(*) AS trip_count\n",
    "    FROM trip_data\n",
    "    GROUP BY DOLocationID\n",
    "    ORDER BY trip_count DESC\n",
    "\"\"\")\n",
    "\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "81245a77-45a0-4e56-9820-afe029c1f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|PULocationID|trip_count|\n",
      "+------------+----------+\n",
      "|          61|    163091|\n",
      "|          76|    134198|\n",
      "|         132|    114179|\n",
      "|          79|    112017|\n",
      "|          37|    110150|\n",
      "|          42|    108070|\n",
      "|         138|    104119|\n",
      "|         244|     97324|\n",
      "|          89|     95724|\n",
      "|          39|     94484|\n",
      "|         231|     94155|\n",
      "|           7|     92676|\n",
      "|          17|     90352|\n",
      "|         161|     90261|\n",
      "|         225|     88749|\n",
      "|         234|     88372|\n",
      "|         230|     86870|\n",
      "|         188|     84347|\n",
      "|          35|     82764|\n",
      "|         168|     82396|\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HV0003 운송사업자의 승차 지역별 트립 건수를 집계하고, \n",
    "#가장 많은 운송사업자순으로 정렬하는 분석 쿼리  hvfhs_license_num\n",
    "\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT PULocationID, COUNT(*) AS trip_count\n",
    "    FROM trip_data\n",
    "    WHERE hvfhs_license_num = 'HV0003'\n",
    "    GROUP BY PULocationID\n",
    "    ORDER BY trip_count DESC\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bde52f26-4203-4cb9-a14e-3b0751a3a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|hvfhs_license_num|trip_count|\n",
      "+-----------------+----------+\n",
      "|           HV0003|   9836763|\n",
      "|           HV0005|   3219535|\n",
      "|           HV0004|    336606|\n",
      "+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 운송사별 운행 건수 비교\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT hvfhs_license_num, COUNT(*) AS trip_count\n",
    "    FROM trip_data\n",
    "    GROUP BY hvfhs_license_num\n",
    "    ORDER BY trip_count DESC\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f932cb6-1526-432b-9067-f90552486b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f1585c0e-3175-4a4c-a5ca-eb544443e49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+----------+-------------------------+----------+-----------------+\n",
      "|hvfhs_license_num|dispatching_base_num|pickup_datetime    |dropoff_datetime   |PULocationID|DOLocationID|SR_Flag|PU_Borough|PU_Zone                  |DO_Borough|DO_Zone          |\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+----------+-------------------------+----------+-----------------+\n",
      "|HV0005           |B02510              |2020-03-01 00:03:40|2020-03-01 00:23:39|81          |159         |NULL   |Bronx     |Eastchester              |Bronx     |Melrose South    |\n",
      "|HV0005           |B02510              |2020-03-01 00:28:05|2020-03-01 00:38:57|168         |119         |NULL   |Bronx     |Mott Haven/Port Morris   |Bronx     |Highbridge       |\n",
      "|HV0003           |B02764              |2020-03-01 00:03:07|2020-03-01 00:15:04|137         |209         |1      |Manhattan |Kips Bay                 |Manhattan |Seaport          |\n",
      "|HV0003           |B02764              |2020-03-01 00:18:42|2020-03-01 00:38:42|209         |80          |NULL   |Manhattan |Seaport                  |Brooklyn  |East Williamsburg|\n",
      "|HV0003           |B02764              |2020-03-01 00:44:24|2020-03-01 00:58:44|256         |226         |NULL   |Brooklyn  |Williamsburg (South Side)|Queens    |Sunnyside        |\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+----------+-------------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        t.*, \n",
    "        z1.Borough AS PU_Borough, \n",
    "        z1.Zone AS PU_Zone, \n",
    "        z2.Borough AS DO_Borough, \n",
    "        z2.Zone AS DO_Zone\n",
    "    FROM trip_data t\n",
    "    LEFT JOIN zone_data z1 \n",
    "        ON t.PULocationID = z1.LocationID\n",
    "    LEFT JOIN zone_data z2 \n",
    "        ON t.DOLocationID = z2.LocationID\n",
    "\"\"\")\n",
    "joined_result.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f751b102-c189-4974-974a-ce483b9d35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_result.createOrReplaceTempView(\"join_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9011ab54-d74f-4086-b801-0877c6e96843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|   PU_Borough|PU_Borough_count|\n",
      "+-------------+----------------+\n",
      "|    Manhattan|         4953140|\n",
      "|     Brooklyn|         3735764|\n",
      "|       Queens|         2437383|\n",
      "|        Bronx|         2086592|\n",
      "|Staten Island|          178818|\n",
      "|      Unknown|             845|\n",
      "|          EWR|             362|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 승차 위치 Borough별 운행 건수\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT PU_Borough, COUNT(*) AS PU_Borough_count\n",
    "    FROM join_data\n",
    "    GROUP BY PU_Borough\n",
    "    ORDER BY PU_Borough_count DESC\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b8ac1aea-1e17-4cd2-ba00-5e2604e2a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|             PU_Zone|PU_Zone_count|\n",
      "+--------------------+-------------+\n",
      "| Crown Heights North|       222094|\n",
      "|        East Village|       183821|\n",
      "|       East New York|       168311|\n",
      "|         JFK Airport|       163734|\n",
      "|   LaGuardia Airport|       155876|\n",
      "|      Bushwick South|       155388|\n",
      "|Central Harlem North|       143389|\n",
      "|TriBeCa/Civic Center|       135712|\n",
      "|            Union Sq|       132693|\n",
      "|      Midtown Center|       128751|\n",
      "|Washington Height...|       126621|\n",
      "|             Bedford|       126228|\n",
      "|             Astoria|       125458|\n",
      "|Flatbush/Ditmas Park|       124289|\n",
      "|  Stuyvesant Heights|       124001|\n",
      "|         Murray Hill|       122731|\n",
      "|Times Sq/Theatre ...|       121628|\n",
      "|          Park Slope|       121576|\n",
      "|        Clinton East|       120732|\n",
      "|            Canarsie|       116669|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 서비스 존별 승차/하차 건수\n",
    "#서비스 존별 승차건수\n",
    "\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT PU_Zone, COUNT(*) AS PU_Zone_count\n",
    "    FROM join_data\n",
    "    GROUP BY PU_Zone\n",
    "    ORDER BY PU_Zone_count DESC\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "62bc0005-c736-4655-9dc1-2428fe32e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|             DO_Zone|DO_Zone_count|\n",
      "+--------------------+-------------+\n",
      "|                  NA|       387758|\n",
      "| Crown Heights North|       224476|\n",
      "|         JFK Airport|       216213|\n",
      "|   LaGuardia Airport|       194943|\n",
      "|       East New York|       172649|\n",
      "|      Bushwick South|       158832|\n",
      "|        East Village|       147732|\n",
      "|Central Harlem North|       136729|\n",
      "|  Stuyvesant Heights|       128945|\n",
      "|             Bedford|       128152|\n",
      "|Washington Height...|       127797|\n",
      "|Flatbush/Ditmas Park|       126958|\n",
      "|             Astoria|       124255|\n",
      "|      Midtown Center|       121771|\n",
      "|            Union Sq|       118345|\n",
      "|          Park Slope|       116900|\n",
      "|TriBeCa/Civic Center|       116345|\n",
      "|            Canarsie|       113966|\n",
      "|Prospect-Lefferts...|       113280|\n",
      "|         Murray Hill|       109306|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 서비스 존별 하차건수\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT DO_Zone, COUNT(*) AS DO_Zone_count\n",
    "    FROM join_data\n",
    "    GROUP BY DO_Zone\n",
    "    ORDER BY DO_Zone_count DESC\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "581672e4-cbd0-49ff-ae32-6cd4e83a0959",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
